{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E6998 – HW3 Solution\n",
    "### Student Columbia Uni: yg2499\n",
    "\n",
    "#### Note: The code is running under Python 2.x version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step A: Crawler (50-points): \n",
    "You will have a crawler that accepts in an array with the following strings, each representing a topic:\n",
    "topics = [“politics”, “astronomy”, “medical”, “music”, “sports”]\n",
    "\n",
    "The crawler is to crawl at least 50 documents per topic, write the text files to a directory names after each topic.  You need to have logic that rejects documents that are less than 50 words, meaning, you will only write crawled content to a text file if it contains at least 50 words.  Your code needs to auto-create the folders (hint: import os).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google\n",
    "import ssl\n",
    "import os\n",
    "import urllib2\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create multiple folders\n",
    "root_path = '/Users/gyang/Desktop/ProjectDataScience/data/hw3/'\n",
    "folders = ['politics', 'astronomy', 'medical', 'music', 'sports']\n",
    "for folder in folders:\n",
    "    os.mkdir(os.path.join(root_path,folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyfolder(theQuery):\n",
    "    fileIndex = list()\n",
    "    \n",
    "    for url in google.search(theQuery, num=200, start=0, stop=20):\n",
    "        fileIndex.append(url)\n",
    "        \n",
    "    cnt = 0\n",
    "    for theUrl in fileIndex:\n",
    "        try:\n",
    "        #for i in range(0,1):\n",
    "            #theUrl = fileIndex[i]\n",
    "            ctx = ssl.create_default_context()\n",
    "            ctx.check_hostname = False\n",
    "            ctx.verify_mode = ssl.CERT_NONE\n",
    "            opener = urllib2.build_opener(urllib2.HTTPSHandler(context=ctx))\n",
    "            opener.addheaders = [('Referer', theUrl)]\n",
    "            html = opener.open(theUrl,timeout=10).read()\n",
    "            soup = BeautifulSoup(html,\"lxml\")\n",
    "        \n",
    "            textTemp = list()\n",
    "            try:\n",
    "                textTemp.append(soup.find('title').text)\n",
    "                textTemp.append('\\n')\n",
    "                for theText in soup.find_all(['p'],text=True): #,'li']):#,'li']):#,'ul']):#,'span']):#,'li']):\n",
    "                    textTemp.append(theText.text)\n",
    "            except:\n",
    "                print(theUrl)\n",
    "                pass    \n",
    "    \n",
    "            text = \" \" . join(textTemp)\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "            if len(text.split()) > 50:\n",
    "                tmpFile = str(cnt) + \".txt\"\n",
    "                indexFile = open(\"/Users/gyang/Desktop/ProjectDataScience/data/hw3/\" +theQuery+\"/\"+ tmpFile, \"w\")\n",
    "                indexFile.write(text.encode('utf8'))\n",
    "                indexFile.close()\n",
    "                cnt = cnt + 1\n",
    "        except:\n",
    "            pass     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.nydailynews.com/news/politics\n",
      "http://www.scouting.org/filestore/Merit_Badge_ReqandRes/Astronomy.pdf\n",
      "https://www.onemedical.com/nyc/doctors/\n",
      "https://www.onemedical.com/\n",
      "https://meps.ahrq.gov/\n",
      "http://www.scouting.org/filestore/healthsafety/pdf/680-001_abc.pdf\n",
      "https://www.polygon.com/2017/11/6/16614664/disney-fox-star-wars-music\n",
      "https://www.hoopladigital.com/browse/music/popular\n",
      "http://www.dailyherald.com/sports/\n"
     ]
    }
   ],
   "source": [
    "#save txt in multiple folders\n",
    "for folder in folders:\n",
    "    classifyfolder(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step B: Classifier (10 points):\n",
    "Using the documents from the crawl, train a model that can be called up to classify arbitrary text into any of the 5 topics. \n",
    "\n",
    "topics = [“politics”, “astronomy”, “medical”, “music”, “sports”]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction\n",
    "from scipy import stats\n",
    "from sklearn import decomposition,linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier,Lasso,SGDClassifier,LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,hamming_loss\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score,precision_recall_curve,f1_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import sklearn\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn import decomposition\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "#from multiscorer import MultiScorer\n",
    "#import seaborn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from bson import json_util\n",
    "from bson.json_util import dumps\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "thePath = '/Users/gyang/Desktop/ProjectDataScience/data/hw3/'\n",
    "\n",
    "#thePathLut = '/Users/gyang/Desktop/ProjectDataScience/code/'\n",
    "theCols = os.walk(thePath).next()[1]\n",
    " \n",
    "theLabels = theCols \n",
    "\n",
    "finalWords = list()\n",
    "theDocs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astronomy', 'medical', 'music', 'politics', 'sports']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this part of code referred by week 3 in class exercise\n",
    "#no modified\n",
    "\n",
    "def genCorpus(theText):\n",
    "    #set dictionaries\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    theStemmer = nltk.stem.porter.PorterStemmer() #Martin Porters celebrated stemming algorithm\n",
    "    \n",
    "    #pre-processing\n",
    "    theText = theText.split()\n",
    "    tokens = [token.lower() for token in theText] #ensure everything is lower case\n",
    "    tokens = [re.sub(r'[^a-zA-Z]+', ' ',token) for token in tokens] #remove special characters but leave word in tact\n",
    "    tokens = [token for token in tokens if token.lower().isalpha()] #ensure everything is a letter\n",
    "    tokens = [word for word in tokens if word not in stopWords] #rid of stop words\n",
    "    tokens = [theStemmer.stem(word) for word in tokens] #stem words uing porter stemming algorithm\n",
    "    tokens = \" \".join(tokens) #need to pass string seperated by spaces       \n",
    "\n",
    "    return tokens\n",
    "\n",
    "def textToNum(theLabels,thePredLabel):\n",
    "    theOutLabel = dict()\n",
    "    cnt = 0\n",
    "    for word in theLabels:\n",
    "        theOutLabel[word] = cnt\n",
    "        cnt = cnt + 1\n",
    "    return str(theOutLabel[thePredLabel])\n",
    "\n",
    "for word in theCols:\n",
    "    cnt = 0\n",
    "    for file in os.listdir(thePath+word):\n",
    "        if file.endswith('.txt'):\n",
    "            try:\n",
    "                f = open(thePath + word + \"/\" + file, \"r\")\n",
    "                lines = f.readlines()\n",
    "                lines = [text.strip() for text in lines]\n",
    "                lines = \" \".join(lines)\n",
    "                finalWords.append(genCorpus(lines))\n",
    "                theDocs.append(textToNum(theLabels,word) +\"_\" + str(cnt))\n",
    "                cnt = cnt +  1\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features =1000,ngram_range =(1,1))\n",
    "tdm = pd.DataFrame(vectorizer.fit_transform(finalWords).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070083</td>\n",
       "      <td>0.107243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.074740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1    2    3    4    5         6    7         8    9   ...   \\\n",
       "0  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.096807  0.0 ...    \n",
       "1  0.0  0.084001  0.0  0.0  0.0  0.0  0.073312  0.0  0.000000  0.0 ...    \n",
       "2  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0 ...    \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0 ...    \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0 ...    \n",
       "\n",
       "        990  991       992       993  994       995  996  997  998  999  \n",
       "0  0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1  0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "2  0.000000  0.0  0.070083  0.107243  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "3  0.069575  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.048842  0.074740  0.0  0.045076  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm.columns= vectorizer.get_feature_names()\n",
    "tdm.index=theDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(tdm)\n",
    "reducedTDM = pd.DataFrame(pca.transform(tdm)) #reduced tdm distance matrix - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reducedTDM.index=theDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcaVar = round(sum(pca.explained_variance_ratio_),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels\n",
    "fullIndex = reducedTDM.index.values\n",
    "fullIndex = [int(word.split(\"_\")[0]) for word in fullIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build models\n",
    "lr = LogisticRegression() #logistic regression\n",
    "svm = LinearSVC() #SVM\n",
    "rfc = RandomForestClassifier() #random forest\n",
    "dtc = DecisionTreeClassifier(max_depth=30) #decision tree\n",
    "abdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),learning_rate=1,algorithm=\"SAMME\",n_estimators=300) #ABDT\n",
    "knn = KNeighborsClassifier() #KNN\n",
    "bag = BaggingClassifier(bootstrap =True) #bagging\n",
    "nn = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15,), random_state=1,alpha=1e-5) #Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr_scores = cross_val_score(lr, reducedTDM,fullIndex, cv=10)\n",
    "svm_scores = cross_val_score(svm, reducedTDM,fullIndex, cv=10)\n",
    "rfc_scores = cross_val_score(rfc, reducedTDM,fullIndex, cv=10)\n",
    "dtc_scores = cross_val_score(dtc, reducedTDM,fullIndex, cv=10)\n",
    "abdt_scores = cross_val_score(abdt, reducedTDM,fullIndex, cv=10)\n",
    "knn_scores = cross_val_score(knn, reducedTDM,fullIndex, cv=10)\n",
    "bag_scores = cross_val_score(bag, reducedTDM,fullIndex, cv=10)\n",
    "nn_scores = cross_val_score(nn, reducedTDM,fullIndex, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losgistic Regression Accuracy: 0.93546248\n",
      "SVM Accuracy: 0.93641827\n",
      "Random Forest Accuracy: 0.78540571\n",
      "Decision Tree Accuracy: 0.89963298\n",
      "Ada Boost Decision Tree Accuracy: 0.93951180\n",
      "KNN Accuracy: 0.90231374\n",
      "Bagging Accuracy: 0.93247647\n",
      "Multi-layer Perceptron Accuracy: 0.93568495\n"
     ]
    }
   ],
   "source": [
    "print(\"Losgistic Regression Accuracy: %0.8f\" % (lr_scores.mean()))\n",
    "print(\"SVM Accuracy: %0.8f\" % (svm_scores.mean()))\n",
    "print(\"Random Forest Accuracy: %0.8f\" % (rfc_scores.mean()))\n",
    "print(\"Decision Tree Accuracy: %0.8f\" % (dtc_scores.mean()))\n",
    "print(\"Ada Boost Decision Tree Accuracy: %0.8f\" % (abdt_scores.mean()))\n",
    "print(\"KNN Accuracy: %0.8f\" % (knn_scores.mean()))\n",
    "print(\"Bagging Accuracy: %0.8f\" % (bag_scores.mean()))\n",
    "print(\"Multi-layer Perceptron Accuracy: %0.8f\" % (nn_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid search parameters tuning\n",
    "lr_grid =GridSearchCV(estimator=lr, param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] })\n",
    "svm_grid = GridSearchCV(estimator=svm,param_grid={\"C\":[1,0.1,0.05,0.01,0.005]})\n",
    "rfc_grid =GridSearchCV(estimator=rfc, param_grid={\"n_estimators\": [10,30,50,100]})\n",
    "dtc_grid =GridSearchCV(estimator=dtc, param_grid={\"max_depth\": [10,30,50,100]})\n",
    "abdt_grid =GridSearchCV(estimator=abdt, param_grid={\"n_estimators\": [10,30,50,100,200,300]})\n",
    "knn_grid =GridSearchCV(estimator=knn,param_grid = dict(n_neighbors=range(1,6)))\n",
    "bag_grid =GridSearchCV(estimator=bag, param_grid={\"n_estimators\": [10,30,50,100]})\n",
    "nn_grid =GridSearchCV(estimator=nn, param_grid={\"alpha\": [1,0.1,0.01,0.001,0.0001,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_fit =lr_grid.fit(reducedTDM,fullIndex)\n",
    "svm_fit =svm_grid.fit(reducedTDM,fullIndex)\n",
    "rfc_fit =rfc_grid.fit(reducedTDM,fullIndex)\n",
    "dtc_fit =dtc_grid.fit(reducedTDM,fullIndex)\n",
    "abdt_fit =abdt_grid.fit(reducedTDM,fullIndex)\n",
    "knn_fit =knn_grid.fit(reducedTDM,fullIndex)\n",
    "bag_fit =bag_grid.fit(reducedTDM,fullIndex)\n",
    "nn_fit =nn_grid.fit(reducedTDM,fullIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bestscore(grid):\n",
    "    bestScore = round(grid.best_score_,4)\n",
    "    parameters = grid.best_params_\n",
    "    return (bestScore,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_bestscores =bestscore(lr_fit)\n",
    "svm_bestscores =bestscore(svm_fit)\n",
    "rfc_bestscores =bestscore(rfc_fit)\n",
    "dtc_bestscores =bestscore(dtc_fit)\n",
    "abdt_bestscores =bestscore(abdt_fit)\n",
    "knn_bestscores =bestscore(knn_fit)\n",
    "bag_bestscores =bestscore(bag_fit)\n",
    "nn_bestscores =bestscore(nn_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR --> Best Score: 0.9365 and Parameters: {'C': 1}\n",
      "SVM --> Best Score: 0.9398 and Parameters: {'C': 0.1}\n",
      "Random Forest --> Best Score: 0.9331 and Parameters: {'n_estimators': 50}\n",
      "Decision Tree --> Best Score: 0.9197 and Parameters: {'max_depth': 50}\n",
      "ABDT --> Best Score: 0.9264 and Parameters: {'n_estimators': 10}\n",
      "KNN --> Best Score: 0.9197 and Parameters: {'n_neighbors': 5}\n",
      "Bagging --> Best Score: 0.9398 and Parameters: {'n_estimators': 50}\n",
      "NN --> Best Score: 0.9298 and Parameters: {'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"LR --> Best Score: \" + str(lr_bestscores[0]) + \" and Parameters: \" + str(lr_bestscores[1]))\n",
    "print(\"SVM --> Best Score: \" + str(svm_bestscores[0]) + \" and Parameters: \" + str(svm_bestscores[1]))\n",
    "print(\"Random Forest --> Best Score: \" + str(rfc_bestscores[0]) + \" and Parameters: \" + str(rfc_bestscores[1]))\n",
    "print(\"Decision Tree --> Best Score: \" + str(dtc_bestscores[0]) + \" and Parameters: \" + str(dtc_bestscores[1]))\n",
    "print(\"ABDT --> Best Score: \" + str(abdt_bestscores[0]) + \" and Parameters: \" + str(abdt_bestscores[1]))\n",
    "print(\"KNN --> Best Score: \" + str(knn_bestscores[0]) + \" and Parameters: \" + str(knn_bestscores[1]))\n",
    "print(\"Bagging --> Best Score: \" + str(bag_bestscores[0]) + \" and Parameters: \" + str(bag_bestscores[1]))\n",
    "print(\"NN --> Best Score: \" + str(nn_bestscores[0]) + \" and Parameters: \" + str(nn_bestscores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model pick up -- Bagging classifier\n",
    "bestmodel =BaggingClassifier(bootstrap =True,n_estimators =50)\n",
    "bestmodel.fit(reducedTDM,fullIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93618017668073283"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bestmodel, reducedTDM,fullIndex, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestmodel.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save best model\n",
    "filename = 'bestmodel.pkl'\n",
    "joblib.dump(bestmodel, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test load the model from disk\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step C.\tStreaming Twitter (10 points):\n",
    "\n",
    "Use the following strings in your streaming twitter app:\n",
    "setTerms = [“potus”, “moon and the sun”, “pharmacy”, “drake”, “quarterback”]\n",
    "You will call up your model and classify (topic variable) the bodies of tweets and store the following in a mongo database:\n",
    "\n",
    "followers, screen_name, friends_count, created_at, message_id, location, topic\n",
    "Export a sample of a test run to a json file called hw3.json.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy  \n",
    "from pymongo import MongoClient\n",
    "from textwrap import TextWrapper\n",
    "from tweepy.utils import import_simplejson\n",
    "json = import_simplejson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamListener(tweepy.StreamListener):  \n",
    "    status_wrapper = TextWrapper(width=140, initial_indent='', subsequent_indent='')    \n",
    "    def on_status(self, status): \n",
    "        tempA = self.status_wrapper.fill(status.text)\n",
    "        tempB = status.retweeted \n",
    "        tempC = status.user.lang \n",
    "        tempD = status.geo\n",
    "        \n",
    "        ############################################################\n",
    "        #embed code here\n",
    "        \n",
    "        testText = list()\n",
    "        testText.append(genCorpus(self.status_wrapper.fill(status.text)))\n",
    "        test = vectorizer.transform(testText)\n",
    "        X2_new = pca.transform(test.toarray())\n",
    "        x = best_model.predict(X2_new)\n",
    "        pred_label =theCols[int(x)]\n",
    "        \n",
    "        \n",
    "        ############################################################\n",
    "        \n",
    "        if (((\"en\" in tempC) and (tempB is False)) and (not(\"RT\") in tempA[:2]) and ((((\"http\" or \"www\") in tempA) and ((' ') in tempA)) or (not(\"http\" or \"www\") in tempA))):\n",
    "        #TO DO\n",
    "            \n",
    "        #tempA is text body\n",
    "            try:     \n",
    "                print(self.status_wrapper.fill(status.text))\n",
    "                mongo_collection.insert({\n",
    "                'topic': pred_label,\n",
    "                'followers': status.user.followers_count,\n",
    "                'screen_name': status.author.screen_name,\n",
    "                'friends_count': status.user.friends_count,\n",
    "                'created_at': status.created_at,\n",
    "                'message_id': status.id,\n",
    "                'location': status.user.location\n",
    "                })\n",
    "            except Exception as e:  \n",
    "            #print(\"HERE\")          \n",
    "                pass \n",
    "        \n",
    "#print(\"here\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step D: Streamline the entire process (30-points)\n",
    "You need to streamline your code, where one execution of code will run through the entire process: crawl  train  Twitter API --> Classify bodies of tweet --> write to mongo\n",
    "The code is to keep the API running, continuously classify tweets and write to mongo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "auth1 = tweepy.auth.OAuthHandler('wNaJv1v48TSxgwS5nsDczvHFt',\n",
    "                                 'f9YAbBkNtA6aRX5TmVQRZNi7QsSMVz9xjedaleTFNAqIQ4w6Co')  \n",
    "auth1.set_access_token('915367239733383168-BRMk1IVhls8HjQTZlErdvKpW8m5prPR',\n",
    "                       'GinBjBKVkP8lqjkfEtfaDKczgawna3yvQ0X6ydGm04w52')  \n",
    "api = tweepy.API(auth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mongo = MongoClient('localhost', 27017)\n",
    "mongo_db = mongo['twitter_hw3']\n",
    "mongo_collection = mongo_db['theData']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Just Use \"Stop\" to stop running kernel,otherwise it will continue running ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@suziferg0806 @itsroseramirez @Michell71375111 @AGates1812 @price1000000 @glynngirls @dgvreiman @dklou76… https://t.co/tuJxD29ZI8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ChooseToBFree @SKYRIDER4438 @KamVTV @SenJohnMcCain @POTUS You can be sure his brain tumor has nothing to do with i… https://t.co/0ih5y8SyG5\n",
      "@thecybermenace @Tia6sc @ChooseToBFree @POTUS Actually it’s PTSD. Post Trump Stupidity Disorder.\n",
      "Since it's beg to look like noone is untouched w/Russia connections in Trump Admin, who'd be left 2 b #POTUS? The 1… https://t.co/6pJHnVoWpx\n",
      "#POTUS  \"tHe CAt N dA hAT iS baCk\"  HEy THX tO \"MR.PREZ &amp; 1st LADY\"❤️  I'm N da LIBERAL'S LIBRARIES &amp; CHRISTMAS🎄TRE…\n",
      "https://t.co/5ZRT5zJ2hn\n",
      "Tonight is the night @bretthundley7 finally becomes an @NFL quarterback. @packers\n",
      "@PatriotGlobal @POTUS Pass!\n",
      "@WorldTvlr @PFields00 @POTUS @CNN CNN. Is a waste of time.  Fake news\n",
      "@CBSNews @POTUS is a whore of the @NRA . Sick people not willing to save American lives.\n",
      "@taino61 @happerose @KatyaCobham @CBSNews @POTUS No one- absolutely NO ONE - is automatically entitled to my respect. It must be earned.\n",
      "@r_little_finger @MichaelMerkt @realDonaldTrump @HillaryClinton I thank GOD every day for our @POTUS 🇺🇸💕\n",
      "@realDonaldTrump @POTUS I don't give a shit about your 'friendship'. I want to know what you are going to do about… https://t.co/jUSVqgQchK\n",
      "@CkcGrandmac @Real_Foghorn @giabean1 @PIRATEDANTRAIN @complxgrl @Heres2Mischief @AlexandraBlues @TechQn @CudaDebbie… https://t.co/zfwR8E8oVY\n",
      "This is why #WeThePeople love @POTUS...he takes charge of EVERY SITUATION &amp; IS NOT PC CORRECT LIKE TBE LIBTARDS WAN…\n",
      "https://t.co/f7bI7TjWIU\n",
      "@realDonaldTrump @POTUS 🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕\n",
      "🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕🖕… https://t.co/FjBBCZSvMf\n",
      "@Jali_Cat @FLOTUS @POTUS Wow - keep dieing your hair sweetie - suits you well\n",
      "'Blem' by Drake (XXXTENTACION Remix)\n",
      "@ComfortablySmug ^ this guy wrote in Bobby Diamond for POTUS in 2012\n",
      "@lizvelic i just wanted to wait until i was home to go to the pharmacy bc i have no clue what i’m doing lmao\n",
      "@realDonaldTrump @POTUS Yes, u gave t WH daycare center a much needed break. &amp; staff doesnt need 2 worry bout u c'i…\n",
      "https://t.co/HR38jmkZSn\n",
      "@Eminem @thegame @HipHopStreetTv @HotNewHipHop @HipHopAvenue @yeezy @Drake @TWISTAgmg @TechN9ne @petplanetvi… https://t.co/1aNNjDhnMO\n",
      "@realDonaldTrump @POTUS No..we are all trying to figure out how the heck you stole the highest office and how to ge… https://t.co/Fbugtjrz6G\n",
      "@Franklin_Graham @POTUS Fake news poll?\n",
      "@Saphina @covfefeartist @POTUS If only KY fox viewers payed attention to facts.  Of course that would be difficult… https://t.co/fIwdU6GE3s\n",
      "the pharmacy is one of my least favorite places\n",
      "@ffootballLIVE And drake over dame right?\n",
      "@justinsink @POTUS @FLOTUS I hope they take your press pass #FakeNews\n",
      "Republican strategic patience when it comes to American mass shootings looks like this  @DLoesch @PhilHollowayEsq… https://t.co/SlNdPRLQxq\n",
      "And of course he only said it was a mental health issue because the shooter was white 👎🏼 #williteverend https://t.co/y8M1eJ4hhl\n",
      "It’s always Drake season https://t.co/52L9VPNQjW\n",
      "@markmobility @EversFam @POTUS Great good\n",
      "Boyyyy you betta hit us with the Take Care 2 soon https://t.co/trDd9inhY5\n",
      "@thehill @catwoman1979 maybe being #DonaldTrump is more important to him than being #President of the United States? @POTUS?\n",
      "@Franklin_Graham @POTUS @NBCNews My thots too Mr Graham! Are their noses growing for fibbing? Probably! 😉👍\n",
      "@renato_mariotti CONGRESS &amp; POTUS YOU WORK FOR US! The gun makers aren't loosing loved ones. Don't make it easy for…\n",
      "https://t.co/uH1MfsUYqv\n",
      "@4US_Workers  @POTUS   https://t.co/xpXmRyenM2 Best &amp;  brighter  With fake resume? Or just cheaters cheating Americ…\n",
      "https://t.co/5hMgQnshtK\n",
      "@StacyLStiles @mamaclaudio @POTUS Bush was about corrupt greed!\n",
      "New EPA advisor believes air is \"a little too clean for optimum health\" #Fail @epa @POTUS @epascottpruitt https://t.co/e6IBlW2QFh\n",
      "@LauraLoomer They are purging corruption and making needed changes now thanks to @POTUS  #MAGA\n",
      "#PresidentTrump Snowman Shirt - It's Ok To Say #MerryChristmas Again https://t.co/m4jblSqXsG @realDonaldTrump @POTUS https://t.co/YVuVvEX4nS\n",
      "Which daugter , im not aware , of who that is sir https://t.co/lSSGJERU9A\n",
      "11-07 NFL Playoffs Quarterback Power Rankings: Tom Brady, Aaron Rodgers Falling? #AaronRodgers https://t.co/07TwStLY3U #aaronrodgers\n",
      "@MichaelViscon12 @FoxNews @POTUS Interesting.  Every rational person realizes that name calling is the lib/Dems fal… https://t.co/Fw254ezru6\n",
      "Seoul getting ready for @POTUS #dprk https://t.co/NVvsVz2QHA\n",
      "@Josh6williams We get the same calls where I work from “US Pharmacy” asking how our Viagra and Cialis is working. H… https://t.co/bMwDIaAUb3\n",
      "@brianstelter She isn't government u have someone who says doesn't talk to POTUS u can't learn anything she loves t… https://t.co/fSkuYGSiip\n",
      "@SenateMajLdr @POTUS I hope Millar will be coming for the both of you soon, turtle head. Lock him up! Republicans h… https://t.co/dvpuCk9oVA\n",
      "Spark - Drake White https://t.co/5yCiUdBynW #country\n",
      "hello drake I am coming 4 u!!!\n",
      "@realDonaldTrump @POTUS Glad we have you\n",
      "Congress is not \"Victim\" in the Drama Triangle; they are the unwitting \"Persecutor\" of inaction until they act in b… https://t.co/XgJgJfbapS\n",
      "@Lil_Skam It’s true though. Not even with the whole Drake thing. He sounds like he’s on heavy doses of Adderall whe… https://t.co/ZJiUNKVjTW\n",
      "@aseitzwald “Clintonworld”? No henny, we are DEMOCRATS. Many of whom supported her run for POTUS.\n",
      "11-07 Alex Smith becomes first Kansas City Chiefs quarterback to win playoff game #KansasCityChiefs https://t.co/ItPc39nCPt\n",
      "@NBCNews is a joke https://t.co/CalX2Tli9W\n",
      "@POTUS @mike_pence you take thaad away sir they people are gone and so is ur border crossing force if need be forget the people we try sir\n",
      "@Franklin_Graham @POTUS Probably a sampling of 60% Democrats and 40% Republicans all from liberal urban districts.\n",
      "@whereveriwant2 @dogaldtrump @Search_deeply @seanthegritty @POTUS Don’t have to go deep. It’s right there on the be… https://t.co/vBdYrRHF93\n",
      "Drake Accuses Coachella-Area Country Club of Racial Profiling | Pitchfork https://t.co/3vzCrQmhDz\n",
      "@BryanDawsonUSA @JuliaFleming @realDonaldTrump @POTUS Done!!!\n",
      "Drake!\n",
      "@3lectric5heep @realDonaldTrump @POTUS @DonaldJTrumpJr THAT IS A BAD DHS NOMINEE!, WHO THE HELL RECOMMENDED HER! AB… https://t.co/ixEt57ceZG\n",
      "@realDonaldTrump @POTUS Try not being yourself, Try being an actual president. Pretend you are a great president li… https://t.co/YT4Bh7U7RC\n",
      "@dawnjoy007 @ProudConse @POTUS Sweden’s police have given up and their govt is set to resign.\n",
      "@TheLastRefuge2 @POTUS @FLOTUS Praying traveling Mercies. for you as you take these trips\n",
      "@FoxNews @GeorgeHWBush @POTUS Past presidents were money-mongers, POTUS now loves humanity of all color.\n",
      "@POTUS has his thumb up his #ss doing nothing. https://t.co/fdVpbso0Lk\n",
      "@Blondetastic1 @Alyssa_Milano @POTUS The #TexasChurchMassacre shooter used an assault rifle, which are not protecte… https://t.co/BcKmPN41cg\n",
      "I would throw my entire body lol https://t.co/fPk2hTklB4\n",
      "aye this a hit already https://t.co/jKjjJHvmGl\n",
      "@HavaBatia @DRUDGE_REPORT @POTUS Hand shake shows mutual respect of equals. Bowing is submissive. The emperor doesn’t bow back.\n",
      "@Evan_McMullin Can any of the 64% including Evan McMullin provide undeniable evidence of any crime/collusion with P… https://t.co/Yc2ESgZ8DD\n",
      "@munroe_dan @POTUS Smart answer! 😆😆😆\n",
      "retreat retreat retreat  #Giants' #McAdoo: #Eli's 'our quarterback,' but others may get playing time  #NYG   https://t.co/FGt09jwXcE\n",
      "@realDonaldTrump @sweetpeach77 I certainly hope so @POTUS I have been there and they are ragheads Sir. Sorry, not PC here.\n",
      "UN was formed more than 70 yrs ago,not to bully the member small nations.@antonioguterres @nikkihaley @Plaid_Macron… https://t.co/ZZdIN1iXb2\n",
      "drake and josh was and still is my shit https://t.co/5slSf2hVSY\n",
      "Nice that the U.S. is at the top of The Onion tweets... @potus @vp @realDonaldTrump https://t.co/uT8kdhlV0f\n",
      "And the same moon, same sun, same air, same earth. https://t.co/IN2aVksNVU\n",
      "@stillgray @DonaldJTrumpJr Don't believe anything the lying criminal media says. Only believe the truth pres Trump… https://t.co/TJzJoH3JEW\n",
      "@latimes Woo @POTUS another bites the dust.   Donald and his corrupt homies are trying to steal our tax dollars for their own pockets!#Maga\n",
      "@mnalimonyreform That's why the POTUS can support this.  He'd be grandfathered in...\n",
      "@realDonaldTrump @POTUS Please don’t do anything stupid that will either start WWIII or further embarrass your country.\n",
      "@POTUS people in churches, because of injustices, etc... Sadly, 24-30 hours later from me saying that, 27 shot dead in Texas church. Yet,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@realDonaldTrump @POTUS If @realDonaldTrump is for another world leader it's a sure sign to be worried, @POTUS hasn… https://t.co/uWebl9T8Yy\n",
      "Can’t wait to hear these new songs Drake been working on ☺️\n",
      "@realDonaldTrump @POTUS Start war for US White supremacy and to Dominate entire World? A New Imperial Power Sir.\n",
      "@crusher614 @jcpenni7k @ChristieC733 @SandraTXAS @Shastina_Eloff @StacyLStiles @Lrihendry @gabriella_akat… https://t.co/lZLrO1BCFk\n",
      "@POTUS @usairforce  I'm sure you're both busy with more important things but this is hard to take! How hard is it t… https://t.co/9xQHpimBtY\n",
      "Been* https://t.co/fozGn8DMqx\n",
      "Happening now at The Drake. I have no idea what “Pickle Battle” is. https://t.co/2NdrpRwyyF\n",
      "#Trump #Weak can’t take finger https://t.co/CpkyeIWkIj\n",
      "Drake snitched\n",
      "@DemOrBust @BeaucageRick @LouDobbs @KrisKobach1787 @POTUS Sounds right.\n",
      "It's Nice to have a @POTUS who will now #Bow to anyone. https://t.co/fNbP1mUEth\n",
      "MBB: Drake Wilks for two!\n",
      "@TeddySandman @FoxNews @realDonaldTrump @POTUS Tribalism will be this country’s downfall. Our descendants will look… https://t.co/EsNyTMkQwB\n",
      "I liked a @YouTube video https://t.co/43CkZN1CaB Drake Type Beat \"Deadstar\" | Free Drake Type Beat 2017\n",
      "@TuckerCarlson @TheJuanWilliams @FoxNews OMG the time has come for fox news to cut ties with Juan Williams. Turning… https://t.co/3PZqFGq9PP\n",
      "@LostNbooks @CBSNews @POTUS Or she caused the marketing business to lose money.\n",
      "To be a successful Packers quarterback you have to have this chinstrap lol https://t.co/qFTWMFSyTy\n",
      "@30621100 @ColonelKek45 @PatriotMAGA @JackPosobiec @POTUS @realDonaldTrump @VP @jeffsessions @doj @FBI Probably fro… https://t.co/YVPs61x4pV\n",
      "@ShaunKing why aren’t you complaining about this? Lazy identity fraud. https://t.co/BVqYDzSE4k\n",
      "@judy_kimble5 @DonaldJTrumpJr Justice did you see this tweet? Awesome isn't it? Many of us are thrilled with the po… https://t.co/PmgNr8zmnC\n",
      "@VP @TrumpTrain45Pac @POTUS Remembering the Innocent lives taken in Texas. Prayers for the departed &amp; for the famil…\n",
      "https://t.co/Mzgass0pvv\n",
      "#BoycottNFL Stand with @POTUS God Bless America!! https://t.co/GGpHmkyk2b\n",
      "I think we'd be better off with Darth Vader as POTUS https://t.co/QPyaSfAa25\n",
      "DRAKE DID THIS 😡😡😡 https://t.co/Lqi8enXSU8\n",
      "@realDonaldTrump @POTUS Military orders?? These are a dead end for the creativity of humanity from the beginning of… https://t.co/WrLNvXoYaH\n",
      "@Kirbywhitt was this the guy you were talking about the other day? https://t.co/bB5vTzdqlr\n",
      "Now Playing on Urban Hitz Radio: Metro Boomin - No Complaints (F. Offset &amp; Drake) *** Listen Now *** https://t.co/7fHaOLT4JD\n",
      "@josephl1331 @CBSNews @POTUS And who makes the rules about being a lady? Certainly not the men!\n",
      "@POTUS Yeah, they must have missed the call but the other 36% are just as Pissed Off at the #TrumpCrimeFamily https://t.co/yCYbbDASdG\n",
      "On the left a true #potus meeting another greater leader.  On the right #barackobama #Obama waiting for… https://t.co/wRR0KSqmqf\n",
      "With all kidding aside: I am happy that you are exposing @TheDemocrats for their cheating, lying, and pure deceit. @gop @LogCabinGOP @potus\n",
      "@SmythRadio Absolutely agree that we all can disagree.  And I always respected the POV of the anti-Syrian strikers,… https://t.co/7FUxuEScSA\n",
      "at least be a cute bra... https://t.co/hCsrfbt4Ye\n",
      "@ABCPolitics Is there no limit to the number of Americans this @POTUS can betray with impunity?\n",
      "@HiddenTara @AlphaOmegaSin @mundanematt @realDonaldTrump @POTUS It's a conspiracy that goes far into the darknet. =P\n",
      "I know it's not really possible, but sometimes it helps to dream it. #StillWithHer #WhatHappened #StrongerTogether… https://t.co/AI9x7Gcwxd\n",
      "Trump's DHS Nominee: Ready to Work with Congress on DACA Amnesty @POTUS -you'll be 1 term prez if you give amnesty  https://t.co/8zIupfdYZ3\n",
      "😡🤯Don't even get me started... https://t.co/txuWfgoJmn\n",
      "@tonysnell @Jali_Cat @FLOTUS @POTUS Try again.  This time actually think before you speak.\n",
      "Can you recommend anyone for this #job? Pharmacy Technician Instructor - Substitute - https://t.co/VEtIC0UhnN #PharmacyTechnician #Hiring\n",
      "@isee61 @djjkim @PressSec @POTUS @realDonaldTrump Not true.\n",
      "@RackzFucknPolo They prolly was drake fans anyway lol\n",
      "@FAIRImmigration @POTUS Trump doesn’t do anything that doesn’t positively effect him.\n",
      "@thanksgivingss @kristinemontel1 @GabSalembabie @JacobAWohl @POTUS The dumb ass liberals who are shooting up the pl… https://t.co/NBXJUX8k9u\n",
      "Drake was the only one to make it outta “Bedrock” Everybody else disappeared and that includes Wayne\n",
      "@realDonaldTrump @POTUS Yeah, vote Retardican...  Look where it's gotten the rest of the country with YOU. Stop try… https://t.co/AoRiBqFU2H\n",
      "@devhancock @SenMikeLee @POTUS @SecretaryZinke Lee makes me ill\n",
      "@FoxNews LMAO H.W. Bush Don't even realize he's even in this world, how can he write a book? just Liberal washed up… https://t.co/MO2yWxMiQz\n",
      "POTUS: RT @realDonaldTrump: I have great confidence in King Salman and the Crown Prince of Saudi Arabia, they know exactly what they are do…\n",
      "POTUS: RT @realDonaldTrump: Getting ready to leave for South Korea and meetings with President Moon, a fine gentleman. We will figure it al…\n",
      "POTUS: RT @realDonaldTrump: My visit to Japan and friendship with PM Abe will yield many benefits, for our great Country. Massive military …\n",
      "Vikings win the game with Jerrick McKinnon running the wildcat https://t.co/O37vejb2jM\n",
      "In other words, YOUR FAVORITE RAPPER WILL BE IRRELEVANT SOON... https://t.co/WL9UicIiEQ\n",
      "@zaynschanels @PopCrave @theweeknd She had a mf nickelodeon show to propell her show, The Weeknd was literally dead… https://t.co/45wT8JJsNT\n",
      "@Franklin_Graham @POTUS Didn't ask me. Guess they asked all liberals.  I think he is doing a terrific job.\n",
      "@realDonaldTrump YOU Fucking caused the TX shooting! Allowing mentally ill to buy guns! Your fault! Your fault! Dumb Donald POTUS!\n",
      "All my fave rappers either get locked up or dead then u forced to hear niggas call Drake the Goat  in the meantime, shyt is wack\n",
      "@KellyannePolls @POTUS I guess some day they will pass out slander tickets (hope) or warnings. and 3 tickets and th… https://t.co/vZaOSp6uOD\n",
      "@mrstreed2011 @EdKrassen @POTUS @realDonaldTrump More direct to your comment I am worried about White Nationalist a… https://t.co/SBdorcFMBR\n",
      "@SafetyPinDaily @Newsweek Well, @IvankaTrump is her @POTUS Daddy's little girl . Who wants to tell her they can't s… https://t.co/QdH0Xloaxj\n",
      "@MarkNapolillo @Real_Foghorn @giabean1 @PIRATEDANTRAIN @complxgrl @Heres2Mischief @AlexandraBlues @TechQn… https://t.co/GESXYTCiji\n",
      "If my dad was in prison I'd get him out, you gonna man up @Drake and do the same? https://t.co/lOVtYtA6iM\n",
      ".@GOP .@SenateGOP .@HouseGOP .@SenateDems .@HouseDemocrats .@POTUS .@VP .@realDonaldTrump  Remove this illegal nepo… https://t.co/ZK1KMo43dy\n",
      "@theoriginalJanH @eimaha1 @justinsink @POTUS @FLOTUS Abe should jump off a bridge...maybe potus will follow?\n",
      "@GovMalloyOffice @POTUS How about fixing CT taxes, maybe people would stop fleeing the state,  oh wait the republic… https://t.co/1yjiWZDsZr\n",
      "🎧 Shut It Down by @drake on @PandoraMusic https://t.co/kyLq4BNklm\n",
      "@thehill @jaredkushner @POTUS @IvankaTrump U LYING CROOKS HEAR THIS? UR GOING 2 JAIL N WE THE PEOPLE OF THE U.S. WI… https://t.co/K5bao3j6YC\n",
      "Trump expresses ‘great confidence’ in Saudi regime accused of political purge - https://t.co/xNhi1HfIR7 - #USPolitics #trump #potus\n",
      "@realDonaldTrump'll be remembered as a @POTUS who quoted \"fiction\" over fact, preferred lies to truth &amp; employed a \"good news\" personal\n",
      "asst\n",
      "Shout out to all my pharmacy techs and pharmacists who think they’re doctors. I wish I had your confidence.\n",
      "@ChooseToBFree @JrcheneyJohn @KamVTV @SenJohnMcCain @POTUS Maybe his poor heel made him stupid. Nah, to easy.\n",
      "https://t.co/XocVM4mei7.   This is a wall potus Trump should have built it makes a lot of sence.\n",
      "Drake listening to Rihanna rap while trying to convince himself he's the better rapper https://t.co/LyiMq6P0HY\n",
      "@tparmer @VP @POTUS Oh silly @tparmer. We only call for extreme vetting of Muslim mass murderers.\n",
      "Every season is drake season 👅 https://t.co/soMzK1Dqpf\n",
      "New poll, 75% of #GOP believe Trump involved with Russia. Meaning a whole lot of them know hostile power influences POTUS - just don't care\n",
      "@Saphina @LeahR77 @Amy_Siskind @realDonaldTrump @POTUS And that’s why Hillary’s not president\n",
      "@realDonaldTrump @POTUS Dear Pres Trump, you are chief law enforcement officer in the land. Y-o-u have the power 2 direct AG SESSONS. BlessU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SenateMajLdr @POTUS Interviewing Supreme Court nominees is your job also but you ignored that job for Obama... you… https://t.co/LIQuH8rnCT\n",
      "It’s always fun when Aunt Jessica is around 🤘🏼 @ Drake Park https://t.co/GJZZ4ALN2Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-8c41cfae61d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstreamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msetTerms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'potus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'moon and the sun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pharmacy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drake'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quarterback'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msetTerms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/contrib/pyopenssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.pyc\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.pyc\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             kevent_list = _syscall_wrapper(self._kqueue.control, True,\n\u001b[0;32m--> 513\u001b[0;31m                                            None, max_events, timeout)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkevent_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/envs/py27/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.pyc\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, recalc_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_SYSCALL_SENTINEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;31m# OSError is thrown by select.select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# IOError is thrown by select.epoll.poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l = StreamListener()  \n",
    "streamer = tweepy.Stream(auth=auth1, listener=l, timeout=3000)   \n",
    "setTerms = ['potus', 'moon and the sun', 'pharmacy', 'drake', 'quarterback']\n",
    "streamer.filter(track =setTerms,languages=['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step D: Export your mongo collection from above to a json file called sample.json.  10-points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract json to local file\n",
    "#method 1\n",
    "c =mongo_collection.find({})\n",
    "\n",
    "with open('hw3.json', 'w') as outfile:\n",
    "    for line in c:\n",
    "        json.dump(line,outfile,default =json_util.default)\n",
    "        outfile.write('\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
